{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory (Auditbot_backend) to the system path\n",
    "sys.path.append(\n",
    "    os.path.abspath(\n",
    "        os.path.join(\n",
    "            os.path.dirname(f\"{os.getcwd()}/chaining.ipynb\"),\n",
    "            '..'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "from utils.preprocessing import *\n",
    "from utils.content_page_parser import *\n",
    "from utils.initialisations import *\n",
    "from utils.db_utils import *\n",
    "from utils.custom_print import *\n",
    "from utils.retriever import *\n",
    "from utils.json_parser import *\n",
    "from utils.prompt_engineering import *\n",
    "from utils.langsmith_trace import *\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG input parameters =======================================================\n",
    "\n",
    "question = \"What are the findings pertaining to grant?\"\n",
    "# query = \"extract finding on weakness in access controls from FY2018/19 to FY2020/21 AGO's report.\"\n",
    "question2 = \"extract finding on weakness in access controls from FY2018/19 to FY2020/21 AGO's report. Tabulate the output with row heading as Year of Report and details of findings.\"\n",
    "\n",
    "# HYPERPARAMETERS ============================================================\n",
    "\n",
    "# preprocessing --------------------------------------------------------------\n",
    "\n",
    "# Chunk into sentences ('s') or paragraphs ('p')\n",
    "chunking='s' \n",
    "\n",
    "# Group smaller chunks into a bigger chunk\n",
    "grouping=1\n",
    "\n",
    "# control minimum chubk size\n",
    "min_chunk_size=100\n",
    "\n",
    "# vector store ---------------------------------------------------------------\n",
    "\n",
    "# add to data base in batches\n",
    "batch_size = 1000\n",
    "\n",
    "# Ranking --------------------------------------------------------------------\n",
    "\n",
    "# top k matches for ranking. \n",
    "# Both sparse and dense search find top_k matches so hybrid search will return \n",
    "# at least top_k matches and most 2 * top_k matches\n",
    "top_k = 30\n",
    "\n",
    "# weights for each retrieval for reciprocal rank fusion\n",
    "weights = [0.5, 0.5]\n",
    "\n",
    "# reciprocal ranking fusion constant\n",
    "k = 60\n",
    "\n",
    "# Reranking ------------------------------------------------------------------\n",
    "\n",
    "# top n matches for reranking\n",
    "top_n = 20\n",
    "\n",
    "# Cross encoder model\n",
    "# claimed to be deprecated because it is bad but seems to still work fine\n",
    "# model_name = \"cross-encoder/stsb-roberta-base\"\n",
    "\n",
    "# best performing on Microsoft tests\n",
    "model_name = \"cross-encoder/ms-marco-MiniLM-L-12-v2\"\n",
    "\n",
    "\n",
    "\n",
    "# IMPROVEMENTS ===============================================================\n",
    "HyDE = False\n",
    "if HyDE:\n",
    "    comments = \"This is using HyDE\"\n",
    "else:\n",
    "    comments = \"None\"\n",
    "\n",
    "# pack parameters for tracing ================================================\n",
    "params = (question, chunking, grouping, min_chunk_size, batch_size, top_k, \n",
    "          weights, k, top_n, model_name, HyDE, comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8488190174102783 seconds\n",
      "number of chunks: 9127\n"
     ]
    }
   ],
   "source": [
    "# RUN ONCE\n",
    "# generate all required data structures\n",
    "\n",
    "# generate chunks\n",
    "generate_chunks(DOCUMENT_DIR,\n",
    "                chunks_path,\n",
    "                chunk_pageNum_pairs_path,\n",
    "                s_p_pairs_path, \n",
    "                chunking, \n",
    "                grouping, \n",
    "                min_chunk_size,\n",
    "                DOC_IDENTIFIER)\n",
    "\n",
    "\n",
    "# generate inverted tree\n",
    "has_content_page = True\n",
    "generate_inverted_tree(chunk_pageNum_pairs_path, \n",
    "                       has_content_page, \n",
    "                       save_inverted_tree_path,\n",
    "                       tree_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique chunks: 8210\n",
      "s_p_pairs will be filled\n"
     ]
    }
   ],
   "source": [
    "# RUN ONCE\n",
    "# retrieve all required data structures\n",
    "inverted_tree = json_file_to_dict(save_inverted_tree_path)\n",
    "\n",
    "# load chunks from tree's keys\n",
    "chunks = list(inverted_tree.keys())\n",
    "print(\"Number of unique chunks:\", len(chunks))\n",
    "\n",
    "# prepare metadata for chromadb\n",
    "pre_metadata = list(inverted_tree.values())\n",
    "metadata = chroma_preprocess_metadata(pre_metadata)\n",
    "\n",
    "# load sentence paragraph pairs\n",
    "if (chunking == 's' or chunking == 'f') and grouping == 1:\n",
    "    print(\"s_p_pairs will be filled\")\n",
    "    s_p_pairs = json_file_to_dict(s_p_pairs_path)\n",
    "else:\n",
    "    s_p_pairs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create db\n",
    "client_dense = chromadb.PersistentClient(path=\"../data/db\", \n",
    "                                   settings = Settings(allow_reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromadb supported model\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "                api_key=OPENAI_API_KEY,\n",
    "                model_name=\"text-embedding-3-small\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromadb's embedding function needs streaming\n",
    "collection = chroma_get_or_create_collection(client_dense, \n",
    "                                             name = \"audit\", \n",
    "                                             embedding_function = openai_ef, \n",
    "                                             reset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of embeddings in database: 8210\n"
     ]
    }
   ],
   "source": [
    "# fill db\n",
    "chroma_fill_db(collection, chunks, metadata, batch_size)\n",
    "print(\"number of embeddings in database:\",collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '50cd72118574', 'cluster_name': 'docker-cluster', 'cluster_uuid': 'l-puMSQDTvqL7nQDfYreOg', 'version': {'number': '8.14.3', 'build_flavor': 'default', 'build_type': 'docker', 'build_hash': 'd55f984299e0e88dee72ebd8255f7ff130859ad0', 'build_date': '2024-07-07T22:04:49.882652950Z', 'build_snapshot': False, 'lucene_version': '9.10.0', 'minimum_wire_compatibility_version': '7.17.0', 'minimum_index_compatibility_version': '7.0.0'}, 'tagline': 'You Know, for Search'}\n",
      "reset index: chromadb_documents\n"
     ]
    }
   ],
   "source": [
    "# RUN ONCE\n",
    "# set up elasticseach for sparse embedding search\n",
    "\n",
    "# create docker container for elasticsearch on terminal/shell\n",
    "'''\n",
    "docker run -p 127.0.0.1:9200:9200 -d --name elasticsearch --network elastic-net \\\n",
    "  -e ELASTIC_PASSWORD=$ELASTIC_PASSWORD \\\n",
    "  -e \"discovery.type=single-node\" \\\n",
    "  -e \"xpack.security.http.ssl.enabled=false\" \\\n",
    "  -e \"xpack.license.self_generated.type=trial\" \\\n",
    "  docker.elastic.co/elasticsearch/elasticsearch:8.14.3\n",
    "'''\n",
    "\n",
    "# connect to the Elasticsearch cluster from python elasticsearch client\n",
    "client_sparce = Elasticsearch(\n",
    "    LOCAL_HOST_URL,\n",
    "    basic_auth=HTTP_AUTH\n",
    ")\n",
    "# checks if client is connected to docker container\n",
    "print(client_sparce.info(http_auth=HTTP_AUTH))\n",
    "\n",
    "# index chunks using elasticsearch (saved in docker)\n",
    "index_elastic_db(client_sparce, index_name, HTTP_AUTH, chunks, reset = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if HyDE:\n",
    "    query = gpt4o(hyde(question), llm)\n",
    "\n",
    "else:\n",
    "    query = question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sparce_retrieval(query):\n",
    "    return bm25_elasticsearch(client_sparce, index_name, HTTP_AUTH, query, top_k)\n",
    "\n",
    "def dense_retrieval(query):\n",
    "    return chromadb_embedding_search(collection, query, top_k)\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"sparce\": sparce_retrieval,\n",
    "        \"dense\": dense_retrieval,\n",
    "        \"query\": RunnablePassthrough()\n",
    "    }\n",
    ")\n",
    "\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def rank(kwargs):\n",
    "    bm25_results = kwargs[\"sparce\"]\n",
    "    embedding_results = kwargs[\"dense\"]\n",
    "    good_chunks = reciprocal_rank_fusion(bm25_results, \n",
    "                                  embedding_results, \n",
    "                                  weights, \n",
    "                                  k)\n",
    "    return {\n",
    "                \"query\": kwargs[\"query\"], \n",
    "                \"good chunks\": good_chunks\n",
    "           }\n",
    "\n",
    "rank = RunnableLambda(rank)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def rerank(kwargs):\n",
    "    query = kwargs[\"query\"]\n",
    "    good_chunks = kwargs[\"good chunks\"]\n",
    "    best_chunks, scores = reranking(model_name, good_chunks, query, top_n)\n",
    "    return {\n",
    "                \"query\": query, \n",
    "                \"best chunks\": best_chunks\n",
    "           }\n",
    "\n",
    "rerank = RunnableLambda(rerank)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def augment(kwargs):\n",
    "    query = kwargs[\"query\"]\n",
    "    best_chunks = kwargs[\"best chunks\"]\n",
    "    prompt = generate_prompt(\n",
    "        query, \n",
    "        inverted_tree, \n",
    "        best_chunks, \n",
    "        chunking, \n",
    "        s_p_pairs)\n",
    "    \n",
    "    return {\n",
    "                \"query\": query,\n",
    "                \"prompt\": prompt\n",
    "           }\n",
    "\n",
    "augment = RunnableLambda(augment)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def generate(kwargs):\n",
    "    query = kwargs[\"query\"]\n",
    "    prompt = kwargs[\"prompt\"]\n",
    "    new_params = (query, ) + params\n",
    "    response = rag_pipeline(new_params, prompt, llm)\n",
    "    return response\n",
    "\n",
    "generate = RunnableLambda(generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m rag \u001b[38;5;241m=\u001b[39m retrieval \u001b[38;5;241m|\u001b[39m rank \u001b[38;5;241m|\u001b[39m rerank \u001b[38;5;241m|\u001b[39m augment \u001b[38;5;241m|\u001b[39m generate\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/base.py:2507\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2505\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2506\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2507\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2508\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/base.py:3985\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3983\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this runnable synchronously.\"\"\"\u001b[39;00m\n\u001b[1;32m   3984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 3985\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3986\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_invoke\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3987\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3988\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3989\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   3993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3995\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/base.py:1599\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1595\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1596\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1597\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1598\u001b[0m         Output,\n\u001b[0;32m-> 1599\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1601\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1602\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1603\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1607\u001b[0m     )\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1609\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/base.py:3853\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   3851\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[1;32m   3852\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3853\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3854\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   3855\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3856\u001b[0m \u001b[38;5;66;03m# If the output is a runnable, invoke it\u001b[39;00m\n\u001b[1;32m   3857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langchain_core/runnables/config.py:380\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    379\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m prompt \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     68\u001b[0m new_params \u001b[38;5;241m=\u001b[39m (query, ) \u001b[38;5;241m+\u001b[39m params\n\u001b[0;32m---> 69\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrag_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langsmith/run_helpers.py:582\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     _container_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    583\u001b[0m _container_end(run_container, outputs\u001b[38;5;241m=\u001b[39mfunction_result)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langsmith/run_helpers.py:579\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m func_accepts_config:\n\u001b[1;32m    578\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 579\u001b[0m     function_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_container\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     _container_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/Desktop/RAG_hdb/utils/langsmith_trace.py:97\u001b[0m, in \u001b[0;36mrag_pipeline\u001b[0;34m(params, prompt, llm, display)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;129m@traceable\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrag_pipeline\u001b[39m(params, prompt, llm, display \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 97\u001b[0m     traced_params \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     98\u001b[0m     response \u001b[38;5;241m=\u001b[39m gpt4o(prompt, llm, display)\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langsmith/run_helpers.py:582\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     _container_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n\u001b[0;32m--> 582\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    583\u001b[0m _container_end(run_container, outputs\u001b[38;5;241m=\u001b[39mfunction_result)\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function_result\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rag/lib/python3.12/site-packages/langsmith/run_helpers.py:579\u001b[0m, in \u001b[0;36mtraceable.<locals>.decorator.<locals>.wrapper\u001b[0;34m(langsmith_extra, *args, **kwargs)\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m func_accepts_config:\n\u001b[1;32m    578\u001b[0m         kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 579\u001b[0m     function_result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_container\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    581\u001b[0m     _container_end(run_container, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/Desktop/RAG_hdb/utils/langsmith_trace.py:58\u001b[0m, in \u001b[0;36mtrace_params\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;129m@traceable\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrace_params\u001b[39m(params):\n\u001b[0;32m---> 58\u001b[0m     (query, chunking, grouping, min_chunk_size, batch_size, top_k, \n\u001b[1;32m     59\u001b[0m      weights, k, top_n, model_name, HyDE, comments) \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[1;32m     62\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomments\u001b[39m\u001b[38;5;124m\"\u001b[39m: comments      \n\u001b[1;32m     92\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 12)"
     ]
    }
   ],
   "source": [
    "rag = retrieval | rank | rerank | augment | generate\n",
    "\n",
    "response = rag.invoke(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
